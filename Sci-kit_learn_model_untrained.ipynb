{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7cad3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.17 s\n",
      "Wall time: 6.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import gc\n",
    "import gradio as gr\n",
    "from datetime import datetime\n",
    "from joblib import dump\n",
    "\n",
    "start_time = datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bccb7d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Importar garbage collector al principio del script\n",
    "\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1952e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Función para cargar y procesar imágenes en lotes utilizando un generador\n",
    "\n",
    "def process_images_in_batches(folder_path, label, target_size, batch_size=10):\n",
    "    file_list = os.listdir(folder_path)\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    with tqdm(total=len(file_list)) as pbar:\n",
    "        for i, filename in enumerate(file_list):\n",
    "            img = imread(os.path.join(folder_path, filename))\n",
    "            if img is not None:\n",
    "                img_resized = resize(img, output_shape=target_size)\n",
    "                all_images.append(img_resized.flatten())\n",
    "                all_labels.append(label)\n",
    "            if (i + 1) % batch_size == 0 or i + 1 == len(file_list):\n",
    "                yield np.array(all_images), np.array(all_labels)\n",
    "                all_images = []\n",
    "                all_labels = []\n",
    "                pbar.update(min(batch_size, len(file_list) - i - 1))\n",
    "                # Liberar memoria eliminando variables no utilizadas y recolector de basura\n",
    "                del img\n",
    "                gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a11b8d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Definir las rutas de los directorios\n",
    "\n",
    "target_size = (200, 200)\n",
    "label_B_train = 0\n",
    "label_N_train = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eefbda20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Directorios de entrenamiento\n",
    "\n",
    "directorio_actual = os.getcwd()\n",
    "\n",
    "folder_path_B_train = os.path.join(directorio_actual, 'TRAIN.1', 'B')\n",
    "folder_path_N_train = os.path.join(directorio_actual, 'TRAIN.1', 'N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "233f54e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3990/4000 [00:58<00:00, 67.82it/s]\n",
      "100%|█████████▉| 3990/4000 [00:58<00:00, 68.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 53s\n",
      "Wall time: 1min 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Procesar imágenes de entrenamiento\n",
    "\n",
    "X_B_train, y_B_train = zip(*list(process_images_in_batches(folder_path_B_train, label_B_train, target_size, batch_size=10)))\n",
    "X_N_train, y_N_train = zip(*list(process_images_in_batches(folder_path_N_train, label_N_train, target_size, batch_size=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "981d0d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.62 s\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Concatenar datos y etiquetas de entrenamiento\n",
    "\n",
    "X_train = np.concatenate(X_B_train + X_N_train, axis=0)\n",
    "y_train = np.concatenate(y_B_train + y_N_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "015539fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Directorios de prueba\n",
    "\n",
    "folder_path_B_test = os.path.join(directorio_actual, 'TEST', 'B')\n",
    "folder_path_N_test = os.path.join(directorio_actual, 'TEST', 'N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9cf9e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 990/1000 [00:14<00:00, 67.01it/s]\n",
      " 99%|█████████▉| 990/1000 [00:14<00:00, 67.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 29.1 s\n",
      "Wall time: 30.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Procesar imágenes de prueba\n",
    "\n",
    "X_B_test, y_B_test = zip(*list(process_images_in_batches(folder_path_B_test, label_B_train, target_size, batch_size=10)))\n",
    "X_N_test, y_N_test = zip(*list(process_images_in_batches(folder_path_N_test, label_N_train, target_size, batch_size=10)))\n",
    "\n",
    "X_test = np.concatenate(X_B_test + X_N_test, axis=0)\n",
    "y_test = np.concatenate(y_B_test + y_N_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fad44c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 19.8 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Normalizar los datos\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f3d799d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda3\\envs\\Python_3115_project\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2h 2min 29s\n",
      "Wall time: 2h 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inicializar el modelo de regresión logística, entrenarlo y hacer predicciones\n",
    "\n",
    "clf = LogisticRegression(solver='saga', max_iter=1000)  # Aumentar el número máximo de iteraciones\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bc5d397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 109 ms\n",
      "Wall time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Evaluar el rendimiento del modelo\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "cls_report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd1f6893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7185\n",
      "Confusion Matrix: \n",
      "[[652 348]\n",
      " [215 785]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.70      1000\n",
      "           1       0.69      0.79      0.74      1000\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.72      0.72      0.72      2000\n",
      "weighted avg       0.72      0.72      0.72      2000\n",
      "\n",
      "Tiempo de ejecución total: 690 minutos y 22 segundos\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Imprimir los resultados de la evaluación\n",
    "\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Confusion Matrix: \\n{conf_mat}\")\n",
    "print(f\"Classification Report: \\n{cls_report}\")\n",
    "\n",
    "end_time = datetime.now()\n",
    "time_diff = end_time - start_time\n",
    "minutes = time_diff.seconds // 60\n",
    "seconds = time_diff.seconds % 60\n",
    "\n",
    "print(f\"Tiempo de ejecución total: {minutes} minutos y {seconds} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a619496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model_filename = 'logistic_regression_model.joblib'\n",
    "dump(clf, model_filename)\n",
    "print(f\"Modelo guardado como {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc96d401",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "566384b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Función para procesar y predecir imágenes utilizando el modelo entrenado\n",
    "\n",
    "def process_image_and_predict(image):\n",
    "    img = np.array(image)\n",
    "    img_resized = resize(img, output_shape=target_size).flatten()\n",
    "    img_resized_scaled = scaler.transform([img_resized])  # Escalar la imagen\n",
    "    prediction = clf.predict(img_resized_scaled)  # Realizar la predicción\n",
    "    etiquetas = {0: 'Biodegradable', 1: 'No Biodegradable'}\n",
    "#    print(f\"Prediction: {prediction}, Label B: {label_B_train}, Label N: {label_N_train}\")\n",
    "    return etiquetas[prediction[0]], prediction[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d245943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 125 ms\n",
      "Wall time: 141 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def mostrar_resultado(imagen):\n",
    "    etiqueta, _ =  process_image_and_predict(imagen)\n",
    "    return f\"La imagen es {etiqueta}.\"\n",
    "iface = gr.Interface(\n",
    "    fn=mostrar_resultado,\n",
    "    inputs=\"image\",\n",
    "    outputs=\"label\",\n",
    "    title=\"Biodegradable o No?\",\n",
    "    description=\"Suba una Imagen para identifcar si es Biodegradable o No!\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee6d0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
